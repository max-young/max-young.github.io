---
layout: post
title: "Celery + RabbitMQ"
date: 2024-02-06
categories: Backend
tags:
  - Python
  - RabbbitMQ
  - Celery
---

- [å‚è€ƒèµ„æ–™](#å‚è€ƒèµ„æ–™)
- [å¯åŠ¨ broker](#å¯åŠ¨-broker)
  - [macOS10.13](#macos1013)
  - [Ubuntu](#ubuntu)
  - [docker](#docker)
- [å®‰è£… Celery](#å®‰è£…-celery)
- [Celery åº”ç”¨](#celery-åº”ç”¨)
- [start Celery worker](#start-celery-worker)
- [start celery beat](#start-celery-beat)
- [è§¦å‘ä»»åŠ¡](#è§¦å‘ä»»åŠ¡)
- [celery command](#celery-command)
- [æµ‹è¯•](#æµ‹è¯•)
- [å…¶ä»–](#å…¶ä»–)
  - [è‡ªå®šä¹‰ task id](#è‡ªå®šä¹‰-task-id)
  - [æ ¹æ® id è·å– task](#æ ¹æ®-id-è·å–-task)
  - [æ›´æ–° state](#æ›´æ–°-state)
  - [å‰ç«¯è·å–è¿›åº¦](#å‰ç«¯è·å–è¿›åº¦)
  - [kill subprocess in celery task](#kill-subprocess-in-celery-task)
  - [kill all tasks](#kill-all-tasks)

## å‚è€ƒèµ„æ–™

[ç”¨ celery å’Œ rabbitmq åšå¼‚æ­¥ä»»åŠ¡è°ƒåº¦](https://vosamo.github.io/2016/05/celery-rabbitmq/)  
[celery å®˜æ–¹æ–‡æ¡£](http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html)  
[ä»»åŠ¡é˜Ÿåˆ—åœ¨ Web æœåŠ¡é‡Œçš„åº”ç”¨](http://blog.csdn.net/nicajonh/article/details/53224783)

## å¯åŠ¨ broker

### macOS10.13

```shell
$ brew install rabbitmq
==> Summary
ğŸº  /usr/local/Cellar/rabbitmq/3.7.4: 232 files, 12.6MB, built in 2 seconds
```

å¯ä»¥çœ‹åˆ°å®‰è£…çš„è·¯å¾„æ˜¯`/usr/local/Cellar/rabbitmq/3.7.4`ï¼Œéœ€è¦å°†æ­¤è·¯å¾„åŠ å…¥åˆ°ç¯å¢ƒå˜é‡é‡Œï¼Œè¿™æ ·æ‰èƒ½ç›´æ¥è¾“å…¥ rabbitmq-server å¯åŠ¨ï¼Œè€Œä¸ç”¨è¾“å…¥å…¨éƒ¨è·¯å¾„ï¼Œå°†ä¸‹é¢çš„å†…å®¹æ·»åŠ åˆ°`.zshrc`é‡Œï¼ˆæ³¨ï¼šä¸ç”¨çš„ shell ä¸åŒçš„æ–‡ä»¶ï¼Œè¿™é‡Œä»¥ zsh ä¸ºä¾‹ï¼‰ï¼š

```shell
PATH=$PATH:/usr/local/Cellar/rabbitmq/3.7.4/sbin
```

å¯åŠ¨

```shell
# å®ˆæŠ¤è¿›ç¨‹å¯åŠ¨æœåŠ¡
$ sudo rabbitmq-server -detached
```

### Ubuntu

```shell
sudo apt-get install rabbitmq-server
```

å®‰è£…ä¹‹åå°±è‡ªåŠ¨å¯åŠ¨äº†  
å¯ä»¥ç”¨è¿™ä¸ªå‘½ä»¤æ¥çœ‹çŠ¶æ€

```shell
systemctl status rabbitmq-server
```

ä¹Ÿå¯ä»¥åœæ­¢å’Œé‡å¯

åˆ›å»ºç”¨æˆ·å¯†ç å’Œ virtual host:

<https://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/rabbitmq.html>

æˆ‘ä»¬åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œäº† rabbitmq, å¯èƒ½è¦ä¾›å¤šä¸ªåº”ç”¨ä½¿ç”¨, é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ç»™ä¸åŒåº”ç”¨åˆ›å»ºä¸åŒçš„ç”¨æˆ·å’Œ virtual host:

```shell
sudo rabbitmqctl add_user myuser mypassword
sudo rabbitmqctl add_vhost myvhost
sudo rabbitmqctl set_permissions -p myvhost myuser ".*" ".*" ".*"
```

ä¹‹ååœ¨åº”ç”¨é‡Œçš„é…ç½®éœ€è¦ç”¨åˆ°, ä¸Šé¢çš„æ–‡æ¡£é‡Œä¹Ÿæœ‰è®²åˆ°  
virtual host çš„ç†è§£: <https://www.cnblogs.com/jxxblogs/p/12260029.html>

### docker

<https://hub.docker.com/_/rabbitmq>

```shell
docker run -d --restart always --hostname systest-rabbit --name systest-rabbit -p 5672:5672 -e RABBITMQ_DEFAULT_USER=simu -e RABBITMQ_DEFAULT_PASS=simu123 -e RABBITMQ_DEFAULT_VHOST=simu rabbitmq:latest
```

this command have config user, password and vhost

## å®‰è£… Celery

```shell
$ pip install celery
```

## Celery åº”ç”¨

åˆ›å»ºä¸€ä¸ª celery åº”ç”¨ application, è¿™ä¸ª app æ˜¯å…¥å£, å¯ä»¥åˆ›å»ºä»»åŠ¡, ç®¡ç† worker ç­‰ç­‰
æˆ‘åœ¨ Django é¡¹ç›®ä¸‹, åœ¨ app ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª tasks.py æ–‡ä»¶, ä»£ç ç¤ºä¾‹å¦‚ä¸‹:

```python
from celery import Celery

app = Celery('tasks', broker='pyamqp://guest@localhost//')

@app.task
def add(x, y):
    return x + y
```

åœ¨ Flask application é‡Œ, å¯ä»¥è¿™ä¹ˆå†™:

```python
from celery import Celery
from celery.schedules import crontab

from . import create_app


def make_celery(flask_app):
    """celery factory
    """
    celery = Celery(flask_app.import_name)
    celery.conf.update(flask_app.config["CELERY_CONFIG"])

    class ContextTask(celery.Task):
        """celery task context
        """

        def __call__(self, *args, **kwargs):
            with flask_app.app_context():
                return self.run(*args, **kwargs)

    celery.Task = ContextTask
    return celery


app = make_celery(create_app())

app.conf.beat_schedule = {
    'cal_everyday': {
        'task': 'surge.tasks.my_task',
        'schedule': crontab(hour=1),
    },
}
app.conf.timezone = 'Asia/Shanghai'


@app.task
def cal_task():
    add.delay(1, 2)


@app.task
def add(x, y):
  print(x + y)
```

## start Celery worker

```shell
celery -A tasks worker --loglevel=info -f /tmp/surge/logs/celery-worker.log
```

`-A`æŒ‡çš„æ˜¯ APPï¼Œå°±æ˜¯å½“å‰çš„ tasks.pyï¼Œå¦‚æœåœ¨æŸä¸ªè·¯å¾„ä¸‹, åˆ™è¾“å…¥å®Œæ•´è·¯å¾„, ä¾‹å¦‚`mmflowproject.tasks`, worker åé¢å¯ä»¥åŠ -c 2 åˆ¶å®š worker æ•°é‡
å¦‚æœè¦å®ˆæŠ¤è¿›ç¨‹è¿è¡Œ, éœ€è¦ç”¨åˆ° supervisord, æš‚ä¸”ä¸è¡¨  
`-f` is log file path

> åœ¨ Django é‡Œé¢å¯ä»¥åŠ ä¸Šé…ç½®
> `DJANGO_SETTINGS_MODULE='fsp.settings_env' celery -A fsp -l info worker`

## start celery beat

```shell
celery -A surge.tasks beat
```

**caution**: celery beat can't work alone, it must work with celery worker, because task is call in the worker, not in beat, beat is only schedule, so we need to start celery worker first. or, if your only have beat task, and only need one worker, you can use this command:

```shell
celery -A surge.tasks worker -B
```

## è§¦å‘ä»»åŠ¡

è¿›å…¥ python shellï¼š

```shell
>>> from tasks import add
>>> add.delay(1, 2)
<AsyncResult: 8d1b69e5-dd51-4194-9d9e-4e5f68a94d81>
```

æˆ‘ä»¬åœ¨ celery worker ä¸‹é¢ä¹Ÿä¼šçœ‹åˆ°æ—¥å¿—:

```shell
...
[2019-06-27 11:37:14,038: INFO/MainProcess] Received task: mmflowproject.tasks.add[d4ab8105-d267-4deb-9957-505d8810cddc]
[2019-06-27 11:37:14,047: INFO/ForkPoolWorker-2] Task mmflowproject.tasks.add[d4ab8105-d267-4deb-9957-505d8810cddc] succeeded in 0.0011335039999949004s: 3
```

è¿™æ ·å°±æ˜¯ä¸€ä¸ªåŸºæœ¬çš„ Celery+RabbitMQ çš„ä¸€ä¸ªåŸºæœ¬çš„è¿‡ç¨‹

## celery command

- get active tasks

```shell
celery -A surge.tasks inspect active
```

- get reserved tasks

```shell
celery -A surge.tasks inspect reserved
```

## æµ‹è¯•

æµ‹è¯•é‡‡ç”¨ mock çš„æ–¹å¼, task å‡½æ•°å•ç‹¬æµ‹è¯•, å‚ç…§å®˜æ–¹æ–‡æ¡£<https://docs.celeryproject.org/en/latest/userguide/testing.html>

## å…¶ä»–

### è‡ªå®šä¹‰ task id

```python
add.apply_async(args, kwargs, task_id=i)
add.apply_async((1, 4), task_id=i)
```

### æ ¹æ® id è·å– task

```python
from celery.result import AsyncResult
from cel.tasks import app

task = app.AsyncResult('432890aa-4f02-437d-aaca-1999b70efe8d')
task.state
```

### æ›´æ–° state

<https://docs.celeryq.dev/en/latest/userguide/tasks.html#custom-states>

æ ¹æ® id è·å–çš„ task, å¦‚æœè¿™ä¸ª task ä¸å­˜åœ¨, task çš„ state æ˜¯ PENDING, å¦‚æœ task è¿˜åœ¨æ‰§è¡Œä¸­, state ä¹Ÿæ˜¯ PENDING, å¦‚ä½•åŒºåˆ†å‘¢?  
æˆ‘ä»¬å¯ä»¥æ›´æ–° task çš„ state:

```python
@celery.task(bind=True)
def push_version(self, token, task_id, version_name, car_id):
    """å¾€è½¦ä¸Šæ¨é€ç‰ˆæœ¬
    """
    self.update_state(state="PROGRESS", meta={"current": 1, "total": 100})
    return
```

meta ä¿¡æ¯å¯ä»¥é€šè¿‡ task.result è·å–

### å‰ç«¯è·å–è¿›åº¦

<https://buildwithdjango.com/blog/post/celery-progress-bars/>

### kill subprocess in celery task

celery task contains subprocess process, if we revoke celery task, the subprocess task will not be killed autonomously, if we want kill them, we can follow this code:

```python
import os
import subprocess

from app import celery_app

def kill_subprocesses_decorator(original_function):
    """kill subprocesses decorator
    """

    def wrapper_function(*args, **kwargs):
        subprocesses = []
        try:
            original_function(subprocesses, *args, **kwargs)
        except Exception:
            print("exception * 100")
            print(subprocesses)
            for pid in subprocesses:
                os.killpg(pid, signal.SIGTERM)
        return

    return wrapper_function

@celery_app.task
@kill_subprocesses_decorator
def my_task(subprocesses, my_arg):
    ...
    process = subprocess.Popen(
        command, shell=True, stdout=subprocess.PIPE,
        stderr=subprocess.PIPE, universal_newlines=True,
        preexec_fn=os.setsid)
    subprocesses.append(os.getpgid(process.pid))
    ...
```

if we revoke:

```python
celery_app.control.revoke(celery_task_id, terminate=True)
```
subprocess will be killed

### kill all tasks

```python
from celery.result import AsyncResult
from app import celery_app

task_ids = []
active_tasks = celery_app.control.inspect().active().values()
pending_tasks = celery_app.control.inspect().reserved().values()
for task in active_tasks:
    for t in task:
        task_ids.append(t["id"])
for task in pending_tasks:
    for t in task:
        task_ids.append(t["id"])

for task_id in task_ids:
    print(task_id)
    result = AsyncResult(task_id, app=celery_app)
    result.revoke(terminate=True)
```
